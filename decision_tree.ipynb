{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cd2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822d40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, chunk_size=10000):\n",
    "    \" small chunk size for small memory capacity\"\n",
    "    \n",
    "    data_frames = []\n",
    "    df_iterator = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "    for i in df_iterator:\n",
    "        data_frames.append(i)\n",
    "\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfe448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218d5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_binary_variables(df):\n",
    "    \"Replace values greater than 1 with 1 for binary columns\"\n",
    "    \n",
    "    binary_cols = [col for col in df.columns if col.startswith('b')]\n",
    "\n",
    "    for col in binary_cols:\n",
    "        df[col] = np.where(df[col] > 1, 1, df[col])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b925e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bedd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"Impute missing values using different strategies based on column types \"\n",
    "    \n",
    "    categorical_cols = [col for col in df.columns if col.startswith('c')]\n",
    "    ordinal_cols = [col for col in df.columns if col.startswith('o')]\n",
    "    numerical_cols = [col for col in df.columns if col.startswith('n')]\n",
    "    binary_cols = [col for col in df.columns if col.startswith('b') and col != 'b17']\n",
    "\n",
    "    # Remove 'Id' and 'b17' from numerical columns\n",
    "    numerical_cols = [col for col in numerical_cols if col not in ['Id', 'b17']]\n",
    "\n",
    "    # Create imputers\n",
    "    numerical_imputer = SimpleImputer(strategy='mean')\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    ordinal_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    binary_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "    # Impute 'c9' with 'Unknown' and remove from categorical columns\n",
    "    if 'c9' in categorical_cols:\n",
    "        df['c9'].fillna('Unknown', inplace=True)\n",
    "        categorical_cols.remove('c9')\n",
    "\n",
    "    # Apply imputers to appropriate columns\n",
    "    df[numerical_cols] = numerical_imputer.fit_transform(df[numerical_cols])\n",
    "    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "    df[ordinal_cols] = ordinal_imputer.fit_transform(df[ordinal_cols])\n",
    "    df[binary_cols] = binary_imputer.fit_transform(df[binary_cols])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc4818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e722c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, columns):\n",
    "    \"Handle outliers using Winsorization\"\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = winsorize(df[col], limits=[0.05, 0.05])  # Winsorize at 5th and 95th percentile remove outlier present \n",
    "                                                           # in extreme level\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c201e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1244f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numeric(df, columns):\n",
    "    \" Normalize numerical columns using StandardScaler \"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cb4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98adfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_categorical(df, categorical_cols):\n",
    "    \" Encode categorical columns using OneHotEncoder\"\n",
    "    \n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    df_encoded = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "    df_encoded.columns = encoder.get_feature_names(categorical_cols)\n",
    "    df = df.drop(categorical_cols, axis=1)\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bb3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d851232e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.30 TiB for an array with shape (2351118, 76011) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_score(target_train,\u001b[38;5;250m \u001b[39my_train_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Encode categorical columns\u001b[39;00m\n\u001b[0;32m     26\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m train_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 27\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mencode_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m encode_categorical(pred_df, categorical_cols)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Split data into features and target\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mencode_categorical\u001b[1;34m(df, categorical_cols)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Encode categorical columns using OneHotEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m df_encoded\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mget_feature_names(categorical_cols)\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(categorical_cols, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:855\u001b[0m, in \u001b[0;36mOneHotEncoder.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X, then transform X.\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m    returned.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[1;32m--> 855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:923\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    917\u001b[0m out \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m    918\u001b[0m     (data, indices, indptr),\n\u001b[0;32m    919\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, feature_indices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m    920\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    921\u001b[0m )\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse:\n\u001b[1;32m--> 923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\sparse\\_base.py:1291\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.30 TiB for an array with shape (2351118, 76011) and data type float64"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    file_path_train = 'assessment/train_df.csv'\n",
    "    file_path_pred = 'assessment/pred_df.csv'\n",
    "    train_df = load_data(file_path_train)\n",
    "    pred_df = load_data(file_path_pred)\n",
    "\n",
    "    # Handle binary variables\n",
    "    train_df = handle_binary_variables(train_df)\n",
    "    pred_df = handle_binary_variables(pred_df)\n",
    "\n",
    "    # Handle missing values\n",
    "    train_df = handle_missing_values(train_df)\n",
    "    pred_df = handle_missing_values(pred_df)\n",
    "\n",
    "    # Handle outliers\n",
    "    numerical_cols = [col for col in train_df.columns if col.startswith('n')]\n",
    "    train_df = handle_outliers(train_df, numerical_cols)\n",
    "    pred_df = handle_outliers(pred_df, numerical_cols)\n",
    "\n",
    "    # Normalize numerical columns\n",
    "    train_df = normalize_numeric(train_df, numerical_cols)\n",
    "    pred_df = normalize_numeric(pred_df, numerical_cols)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = [col for col in train_df.columns if col.startswith('c')]\n",
    "    train_df = encode_categorical(train_df, categorical_cols)\n",
    "    pred_df = encode_categorical(pred_df, categorical_cols)\n",
    "\n",
    "    # Split data into features and target\n",
    "    features_train = train_df.drop(['Id', 'b17'], axis=1)\n",
    "    target_train = train_df['b17']\n",
    "    features_pred = pred_df.drop(['Id'], axis=1)\n",
    "\n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(features_train, target_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(features_pred)\n",
    "\n",
    "    # Prepare submission DataFrame\n",
    "    submission = pd.DataFrame({'id': pred_df['Id'], 'b17': y_pred})\n",
    "\n",
    "    # Save submission to CSV\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    y_train_pred = clf.predict(features_train)\n",
    "    print(f\"F1-Score: {f1_score(target_train, y_train_pred):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1823681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
